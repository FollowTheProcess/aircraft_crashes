{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_profiling import ProfileReport\n",
    "import altair as alt\n",
    "import altair_data_server\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import wordcloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.data.load_data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a word frequency list for summary\n",
    "cv = CountVectorizer(stop_words = \"english\")\n",
    "\n",
    "cv_fit = cv.fit_transform(df['summary'])\n",
    "\n",
    "\n",
    "words = cv.get_feature_names()\n",
    "counts = np.asarray(cv_fit.sum(axis = 0))\n",
    "\n",
    "# Cast to dictionary of word: frequency\n",
    "wordcount_dict = dict(zip(words, counts[0]))\n",
    "\n",
    "# Make a dataframe from dict and sort by frequency\n",
    "word_df = pd.DataFrame.from_dict(wordcount_dict, orient=\"index\", columns = [\"Count\"]).reset_index().rename(columns = {\"index\": \"Word\"}).sort_values(\"Count\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(word_df.nlargest(20, \"Count\")).mark_bar().encode(\n",
    "    x = alt.X(\"Word:N\", title = \"Word\", sort = \"-y\"),\n",
    "    y = alt.Y(\"Count:Q\", title = \"Frequency\")\n",
    ").properties(\n",
    "    title = \"20 Most Common words in Crash Summary\",\n",
    "    height = 500,\n",
    "    width = 750\n",
    ").configure_axisX(labelAngle = -40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good start but I think we can do a little better:\n",
    "\n",
    "* The most common word is \"crashed\" I think that should go without saying really!\n",
    "* Other words like \"aircraft\", \"plane\" etc are also a bit redundant.\n",
    "\n",
    "Really, what I'm looking for here are occurences of words like \"engine\", \"weather\" etc.\n",
    "\n",
    "So to start improving this I'm going to add some of these redundant words to the stop_words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_stop_words = [\n",
    "    \"aircraft\",\n",
    "    \"plane\",\n",
    "    \"crash\",\n",
    "    \"crashed\",\n",
    "    \"flight\"\n",
    "]\n",
    "\n",
    "new_stop_words = list(cv.get_stop_words().union(set(crash_stop_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a word frequency list for summary\n",
    "cv = CountVectorizer(stop_words = new_stop_words)\n",
    "\n",
    "cv_fit = cv.fit_transform(df['summary'])\n",
    "\n",
    "\n",
    "words = cv.get_feature_names()\n",
    "counts = np.asarray(cv_fit.sum(axis = 0))\n",
    "\n",
    "# Cast to dictionary of word: frequency\n",
    "wordcount_dict = dict(zip(words, counts[0]))\n",
    "\n",
    "# Make a dataframe from dict and sort by frequency\n",
    "word_df = pd.DataFrame.from_dict(wordcount_dict, orient=\"index\", columns = [\"Count\"]).reset_index().rename(columns = {\"index\": \"Word\"}).sort_values(\"Count\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(word_df.nlargest(20, \"Count\")).mark_bar().encode(\n",
    "    x = alt.X(\"Word:N\", title = \"Word\", sort = \"-y\"),\n",
    "    y = alt.Y(\"Count:Q\", title = \"Frequency\")\n",
    ").properties(\n",
    "    title = \"20 Most Common words in Crash Summary\",\n",
    "    height = 500,\n",
    "    width = 750\n",
    ").configure_axisX(labelAngle = -40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe the done thing at this point is to make a pretty word cloud...\n",
    "\n",
    "Cue googling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_summary_text = \" \".join(summary for summary in df['summary'])\n",
    "cloud = wordcloud.WordCloud(stopwords = new_stop_words).generate(all_summary_text)\n",
    "\n",
    "plt.imshow(cloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf_idf_vec = TfidfVectorizer(stop_words = new_stop_words)\n",
    "\n",
    "X = tf_idf_vec.fit_transform(df['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "km = KMeans()\n",
    "\n",
    "km.fit(X)\n",
    "\n",
    "labels = km.predict(X)\n",
    "\n",
    "df['cluster_labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "n_clusters = km.cluster_centers_.shape[0]\n",
    "\n",
    "terms = tf_idf_vec.get_feature_names()\n",
    "for i in range(n_clusters):\n",
    "    print(f\"Cluster {i}: \")\n",
    "    for ind in centroids[i, :10]:\n",
    "        print(f\" {terms[ind]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}